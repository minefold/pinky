#!/usr/bin/env ruby

# backup-world <id> <destination> [compress-args]

require 'tempfile'

S3CURL = File.expand_path File.join __FILE__, '../s3curl'
ARCHIVE_DIR = File.expand_path File.join __FILE__, '../archive-dir'

ENVIRONMENT = ENV['ENV'] || 'development'
BUCKET = "minefold-#{ENVIRONMENT}"

def s3size bucket, key
  size = `#{S3CURL} --id minefold --head -- https://#{bucket}.s3.amazonaws.com/#{key} --silent --show-error | grep Content-Length`.strip
  
  size.split(': ').last.to_i
end

require 'find'
def dir_size(dir_path)
  size = 0
  Find.find(dir_path) { |f| size += File.size(f) if File.file?(f) }
  size
end

def run cmd
  $stderr.puts cmd
  success = system cmd
  raise "Failed: '#{cmd}'" unless success
end

id, destination, *compress_args = ARGV

compress_args ||= ['--include level --exclude .']

backup_dir = File.expand_path File.join destination, 'backup'
working_dir = File.expand_path File.join destination, 'working'

raise "working directory does not exist" unless File.exists? working_dir

tar_size = nil
working_dir_size = dir_size(working_dir)

Dir.chdir(working_dir) do
  # as a safeguard I'm uploading backup copies
  keys = [
    "worlds/#{id}/world-data.incremental.tar.lzo",
    "world-backups/#{id}/world-data.incremental.#{Time.now.to_i}.tar.lzo"
  ].each do |key|
    run "#{ARCHIVE_DIR} s3://#{BUCKET}/#{key} #{compress_args.join(' ')}"
  end
end

